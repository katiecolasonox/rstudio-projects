---
title: "Tackling Environmental Justice with One Backpack"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

## Libraries Needed 
```{r}
library(factoextra)
library(dplyr)
library(data.table)
library(ggplot2)
library(maps)
```

## Loading & Subsetting Data
```{r}

#EJI Data
eji = read.csv("C:/Users/Katie/Desktop/EJI.csv")
eji_ny = eji[which(eji$StateDesc == 'New York'),]
eji_ny = eji_ny[which(eji_ny$COUNTY == 'New York' | eji_ny$COUNTY == "Bronx" | eji_ny$COUNTY == "Kings" | eji_ny$COUNTY == "Queens"), ]
```

```{r}
#PM2.5 Data
pops_2.5_walk1 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk1.csv") #ny 
pops_2.5_walk1$walk = 1

pops_2.5_walk2 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk2.csv") #ny
pops_2.5_walk2$walk = 2

pops_2.5_walk3 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk3.csv") #ny
pops_2.5_walk3$walk = 3

pops_2.5_walk4 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk4.csv") #ny
pops_2.5_walk4$walk = 4

pops_2.5_walk5 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk5.csv") #ny
pops_2.5_walk5$walk = 5

pops_2.5_walk6 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk6.csv") #ny
pops_2.5_walk6$walk = 6

pops_2.5_walk7 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk7.csv") #ny
pops_2.5_walk7$walk = 7

pops_2.5_walk8 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk8.csv") #ny
pops_2.5_walk8$walk = 8

pops_2.5_walk9 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk9.csv") #ny/kings
pops_2.5_walk9$walk = 9

pops_2.5_walk10 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk10.csv") #ny
pops_2.5_walk10$walk = 10

pops_2.5_walk11 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk11.csv") #ny
pops_2.5_walk11$walk = 11

pops_2.5_walk12 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk12.csv") #ny
pops_2.5_walk12$walk = 12

pops_2.5_walk13 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk13.csv") #ny
pops_2.5_walk13$walk = 13

pops_2.5_walk14 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk14.csv") #ny
pops_2.5_walk14$walk = 14

pops_2.5_walk15 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk15.csv") #ny
pops_2.5_walk15$walk = 15

pops_2.5_walk16 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk16.csv") #kings
pops_2.5_walk16$walk = 16

pops_2.5_walk17 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk17.csv") #kings
pops_2.5_walk17$walk = 17

pops_2.5_walk18 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk18.csv") #ny/bronx
pops_2.5_walk18$walk = 18

pops_2.5_walk19 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk19.csv") #ny/bronx
pops_2.5_walk19$walk = 19

pops_2.5_walk20 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk20.csv") #ny/bronx
pops_2.5_walk20$walk = 20

pops_2.5_walk21 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk21.csv") #ny
pops_2.5_walk21$walk = 21

pops_2.5_walk22 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk22.csv") #ny
pops_2.5_walk22$walk = 22

pops_2.5_walk23 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk23.csv") #ny
pops_2.5_walk23$walk = 23

pops_2.5_walk24 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk24.csv") #ny
pops_2.5_walk24$walk = 24

pops_2.5_walk25 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk25.csv") #ny
pops_2.5_walk25$walk = 25

pops_2.5_walk26 = read.csv("C:/Users/Katie/Desktop/NYC_POPS_DATA/NYC_POPS_PAM_pm1_pm25_walk26.csv") #ny
pops_2.5_walk26$walk = 26

pops_2.5_allwalks = rbind(pops_2.5_walk1,pops_2.5_walk2, pops_2.5_walk3, pops_2.5_walk4, pops_2.5_walk5, pops_2.5_walk6, pops_2.5_walk7, pops_2.5_walk8, pops_2.5_walk9, pops_2.5_walk10, pops_2.5_walk11, pops_2.5_walk12, pops_2.5_walk13, pops_2.5_walk14, pops_2.5_walk15, pops_2.5_walk16, pops_2.5_walk17, pops_2.5_walk18, pops_2.5_walk19, pops_2.5_walk20, pops_2.5_walk21, pops_2.5_walk22, pops_2.5_walk23, pops_2.5_walk24, pops_2.5_walk25, pops_2.5_walk26)

allwalks = pops_2.5_allwalks[which(pops_2.5_allwalks$TimeUTC != "NaT"), ]
  
allwalks$COUNTY = ifelse(allwalks$walk >= 1 & allwalks$walk <= 15, "New York",
                   ifelse(allwalks$walk >= 16 & allwalks$walk <= 17, "Kings",
                   ifelse(allwalks$walk >= 18 & allwalks$walk <= 26, "New York", "Pending")))

allwalks[5535:5831, 13] = "Kings" #walk 9
allwalks[11584:11681, 13] = "Bronx" #walk 18
allwalks[11897:12215, 13] = "Bronx" #walk 19
allwalks[12392:12829, 13] = "Bronx" #walk 20


allwalks_base = allwalks %>%
  select(TimeUTC, PM25_POPS, walk, COUNTY)

```

## Variables of Interest 
1. Name of Census Tract
2. E_TOTPOP # estimated total population from 2014-2018
3. E_OZONE # annual mean days above O3 regulatory standard (3-year average)
4. E_PM # annual mean days above PM2.5 regulatory standards (3-year average)
5. E_PARK #proportion of census tract's area within 1 mi buffer of green space
6. E_AIRPORT #proportion of census tract's area within 1 mi buffer of airport 
7. E_TOTCR #probability of contracting cancer over the course of a lifetime assuming continous exposure 

8. RPL_EJI # EJI rank
9. RPL_EBM # environmental burden rank
10. RPL_SVM # social vulnerability module rank
11. RPL_HVM # percentile rank of combined tertile (health risks) flags

12. EP_MINRTY # percentage of minority persons
13. EP_POV200 # percentage below 200% poverty
14. EP_CANCER # percentage of individuals with cancer
15. EP_ASTHMA # percentage of individuals with asthma
16. EP_LIMENG # percentage of persons (5+) who speak English "less than well"
17. EP_DISABL # percentage of persons who are disabled
18. EP_AGE65 # percentage of persons aged 65 and older
19. EP_UNINSUR # percentage or persons uninsured 
20. EP_UNEMP # percentage of persons with no high school diploma (25+)

## Base Model
1. Name of Census Tract (index column)
2. E_PM # annual mean days above PM2.5 regulatory standards (3-year average)
3. E_TOTCR # probability of contracting cancer over the course of a lifetime assuming continuous exposure 
4. EP_MINRTY # percentage of minority persons
5. RPL_EJI # EJI rank
6. RPL_SVM # social vulnerability module rank
7. E_TOTPOP # estimated total population from 2014-2018

## Base Model
### Exploratory Analysis 
#### EJI Box Plots & Summary Statistics 
```{r}

#Base Model Variables
eji_base = eji_ny %>%
  select(NAME, COUNTY, E_PM, E_TOTCR, EP_MINRTY, RPL_EJI, RPL_SVM, E_TOTPOP)

#Summary Statistics
eji_base %>%
  group_by(COUNTY) %>%
  summarise(median_min = median(EP_MINRTY), mean_min = mean(EP_MINRTY))

#Categorizing majority "minority" counties
  #This is based on the average % of minorities in each county
eji_base$minority = ifelse(eji_base$EP_MINRTY >= 87 & eji_base$COUNTY == "Bronx", "minority", 
                    ifelse(eji_base$EP_MINRTY >= 62 & eji_base$COUNTY == "Kings", "minority",
                    ifelse(eji_base$EP_MINRTY >= 51 & eji_base$COUNTY == "New York", "minority",
                    ifelse(eji_base$EP_MINRTY >= 72 & eji_base$COUNTY == "Queens", "minority", "non-minority"))))

#Box plot of NY Counties and Rank of EJI 
  #Minority counties def have a higher EJI rank than non-minority counties
  #New York county has the biggest disparity
ggplot(eji_base, aes(x= COUNTY, y=RPL_EJI, fill = minority)) + 
    geom_boxplot() +
    coord_flip() +
    scale_fill_manual(values = c("darkseagreen", "burlywood3")) +
    #geom_jitter(position = position_jitter(0.15)) +
    theme_classic() +
    labs(x = "New York Counties", y = "Rank of EJI")

#Box plot of NY counties vs Above Pm2.5 Regulatory Standards
  #There is not a substantial difference between minority and non-minority counties. 
  #Queens does have the largest spread.
ggplot(eji_base, aes(x= COUNTY, y=E_PM, fill = minority)) + 
    geom_boxplot() +
    coord_flip() +
    scale_fill_manual(values = c("darkseagreen", "burlywood3")) +
    #geom_jitter(position = position_jitter(0.15)) +
    theme_classic() +
    labs(x = "New York Counties", y = "Annaul Mean Days Above PM2.5 Regulatory Standards")

#Box plot of NY counties vs Social Vulnerability Rank
  #Minority counties have a higher social vulnerability rank than non-minority counties
  #Kings and Queens have the largest spread
  #New York has the biggest difference between non-minority and minortiy counties
ggplot(eji_base, aes(x= COUNTY, y=RPL_SVM, fill = minority)) + 
    geom_boxplot() +
    coord_flip() +
    scale_fill_manual(values = c("darkseagreen", "burlywood3")) +
    #geom_jitter(position = position_jitter(0.15)) +
    theme_classic() +
    labs(x = "New York Counties", y = "Social Vulnerability Rank")

```

### Histograms of CDC vs Backpack Campaign 
#### CDC
```{r}

#Loading in CDC estimated daily concentration levels for PM2.5 
  #Am only using 2016 - Aug and July - for a direct comparison to Backpack campaign
  #Also only looking at the four new york counties of interest
  #EJI uses these predicted values from 2014-2016
CDC_PM25 = read.csv("C:/Users/Katie/Desktop/CDC Daily Concentration Levels.csv")
CDC_PM25_sub = CDC_PM25[which((CDC_PM25$countyfips == 5 | CDC_PM25$countyfips == 61 | CDC_PM25$countyfips == 47 | CDC_PM25$countyfips == 81) & CDC_PM25$year == 2016), ]

#Renaming the counties 
CDC_PM25_sub$county = ifelse(CDC_PM25_sub$countyfips == 5, "Bronx",
                      ifelse(CDC_PM25_sub$countyfips == 47, "Kings",
                      ifelse(CDC_PM25_sub$countyfips == 61, "New York", "Queens")))

#Changing county variable to factor
CDC_PM25_sub$county = as.factor(CDC_PM25_sub$county)

#Histogram of CDC estimated PM2.5 for these coutnies 
  #For July & Aug of 2016 the range for the daily PM2.5 is about 0 to 20 for each county
ggplot(CDC_PM25_sub, aes(x=PM25_pop_pred, fill = county)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  facet_wrap(~county) +
  xlab("Predicted PM2.5 Concentration Levels") +
  ylab("Frequency of PM2.5 Levels")

summary(CDC_PM25_sub$PM25_pop_pred)
#Min = 3.209, #Median = 9.065, #Max = 17.481

```

#### Backpacking Campaign
```{r}
#Creating a day variable from the TimeUTC var. 
  #Removing some outliers for more easy comparison
allwalks_base$day = sub("^\\d+/([0-9]+)/\\d+.*", "\\1", allwalks_base$TimeUTC)
allwalks_base = allwalks_base[which(allwalks_base$PM25_POPS <= 150), ]

#Histogram of Backpacking PM2.5 by county
  #This is not an average by the PM2.5 seen every 15 minutes for each walk
  #The range here is much higher than CDC.
  #We are seeing much higher levels of PM2.5
ggplot(allwalks_base, aes(x=PM25_POPS, fill = COUNTY)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  facet_wrap(~COUNTY) +
  xlab("Backpack Campaign Concentration Levels") +
  ylab("Frequency of PM2.5 Levels")

#Averaging the PM2.5 by day 
allwalks_base_grouped = allwalks_base %>%
  group_by(day, COUNTY) %>%
  summarise(PM25_avg = mean(PM25_POPS, na.rm = TRUE))

#Histogram of the backpacking campaign of the average PM2.5 per day by county
  #Still averaging it shows that there are higher reading for PM2.5 compared to CDC predicted 
ggplot(allwalks_base_grouped, aes(x=PM25_avg, fill = COUNTY)) +
  geom_histogram(color="#e9ecef", alpha=0.6, position = 'identity') +
  facet_wrap(~COUNTY) +
  xlab("Backpack Campaign Concentration Levels") +
  ylab("Frequency of PM2.5 Levels")

summary(allwalks_base$PM25_POPS)
#Min = 1.382, Median = 15.778, #3rd Quartile = 29.050 #Max = 423

```

## Bronx clustering analysis
### Base Model
#### Training Data
```{r}

eji_base_bronx = eji_base[which(eji_base$COUNTY == 'Bronx'),]
eji_base_bronx = na.omit(eji_base_bronx)

#Finding what variables to use from base model

library(caret)
correlation_matrix = cor(eji_base_bronx[, c(3:8)]) #EP_MINRTY, RPL_SVM, RPL_EJI

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_base_bronx)), size = 231)
train = eji_base_bronx[train_sample, ]
test = eji_base_bronx[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 61.5%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
library(cluster)
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.66 <- could potentially have a better algorithm

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))
# 75% are in cluster 2 (higher ratings) <- minorities
# 25% are in cluster 1 (lower ratings) <- non-minorities

table(train$km.group, train$minority)

# cluster two has 75% of minority groups

# Are there significant differences?

aov_test = aov(RPL_EJI ~ km.group, data = train)
summary(aov_test) #yes there are significant differences 

aov_test = aov(RPL_SVM ~ km.group, data = train)
summary(aov_test) #yes there are significant differences 

aov_test = aov(E_PM ~ km.group, data = train)
summary(aov_test) #yes there are significant differences

```

#### Testing Data
```{r}


# Setting seed 
set.seed(123)

z = test[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 68.7%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.68 <- could potentially have a better algorithm
# all of cluster 1 remains under the average and has some negative values

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))
# 88% are in cluster 1 (higher ratings) <- minorities
# 12% are in cluster 2 (lower ratings) <- non-minorities

table(test$km.group, test$minority)

# cluster 1 has 100% of minority groups

# Are there significant differences?

aov_test = aov(RPL_EJI ~ km.group, data = test)
summary(aov_test) #yes there are significant differences 

aov_test = aov(RPL_SVM ~ km.group, data = test)
summary(aov_test) #yes there are significant differences 

aov_test = aov(E_PM ~ km.group, data = test)
summary(aov_test) #yes there are significant differences

```

### More Complex Model
#### Training Data 
```{r}

eji_base_bronx = eji_ny[which(eji_base$COUNTY == 'Bronx'),]
eji_base_bronx = na.omit(eji_base_bronx)

#Finding what variables to use from base model
#Above 0.60
correlation_matrix = cor(eji_base_bronx[, c(11:118)])
correlation_matrix

#RPL_EJI 
#EP_MINRTY
#EP_POV200 # estimate below 200% Poverty line
#EP_NONHSDP # No high school degree
#EP_RENTER # estimate of renters
#EP_HOUBDN # households that make less than 75,000
#ELP_NOINT # Percentile rank of persons with no internet

#EP_ASTHMA # percentage with asthma
#F_CANCER # flag indicating tracts greater than 0.67 percentile rank with cancer
#EP_DIABETES # percentage of individuals with diabetes 
#F_HVM # total number of tertile flags
#EP_MHLTH # percentage of individuals reporting not good mental health 

eji_complex_bronx = eji_base_bronx[, c("NAME", "COUNTY", "RPL_EJI", "EP_MINRTY", "EP_POV200",  "EP_NOHSDP", "EP_RENTER",  "EP_HOUBDN", "EPL_NOINT", "EP_ASTHMA","F_CANCER",  "EP_DIABETES",  "F_HVM",  "EP_MHLTH")]

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_complex_bronx)), size = 231)
train = eji_complex_bronx[train_sample, ]
test = eji_complex_bronx[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 48.3%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.45 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))
                    
# 67% are in cluster 1 (higher ratings) <- minorities
# 33% are in cluster 2 (lower ratings) <- non-minorities

# higher across the board for everything except for the flag for cancer 

```

#### Testing Data
```{r}

# Normalizing the data

z = test[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 46.4%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.45 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))
                    
# 73% are in cluster 2 (higher ratings) <- minorities
# 27% are in cluster 1 (lower ratings) <- non-minorities

# higher across the board for everything except for the flag for cancer 


```


## New York clustering analysis
### Base Model
#### Training Data
```{r}

eji_base_ny = eji_base[which(eji_base$COUNTY == 'New York'),]
eji_base_ny = na.omit(eji_base_ny)

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_base_ny)), size = 195)
train = eji_base_ny[train_sample, ]
test = eji_base_ny[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 78.7%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.66 <- could potentially have a better algorithm

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))

# 61% are in cluster 1 (lower ratings) <- non-minorities
# 39% are in cluster 2 (higher ratings) <- minorities 
   # same as the bronx 
   # lower E_PM but higher everything else

table(train$km.group, train$minority)

# cluster 1 has 5% of minority groups

# Are there significant differences?

aov_test = aov(RPL_EJI ~ km.group, data = train)
summary(aov_test) #yes there are significant differences 

aov_test = aov(RPL_SVM ~ km.group, data = train)
summary(aov_test) #yes there are significant differences 

aov_test = aov(E_PM ~ km.group, data = train)
summary(aov_test) #yes there are significant differences

```

#### Testing Data
```{r}

# Setting seed 
set.seed(123)

z = test[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 77.2%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.64 <- could potentially have a better algorithm

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))
# 56% are in cluster 1 (higher ratings) <- non-minorities
# 44% are in cluster 2 (lower ratings) <- minorities

table(test$km.group, test$minority)

# cluster 1 has 14% of minority groups

# Are there significant differences?

aov_test = aov(RPL_EJI ~ km.group, data = test)
summary(aov_test) #yes there are significant differences 

aov_test = aov(RPL_SVM ~ km.group, data = test)
summary(aov_test) #yes there are significant differences 

aov_test = aov(E_PM ~ km.group, data = test)
summary(aov_test) #yes there are significant differences

```

### More Complex Model
#### Training Data 
```{r}

eji_base_ny = eji_ny[which(eji_ny$COUNTY == 'New York'),]
eji_base_ny = na.omit(eji_base_ny)

eji_complex_ny = eji_base_ny[, c("NAME", "COUNTY", "RPL_EJI", "EP_MINRTY", "EP_POV200",  "EP_NOHSDP", "EP_RENTER",  "EP_HOUBDN", "EPL_NOINT", "EP_ASTHMA","F_CANCER",  "EP_DIABETES",  "F_HVM",  "EP_MHLTH")]

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_complex_ny)), size = 231)
train = eji_complex_ny[train_sample, ]
test = eji_complex_ny[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 57%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.49 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))
                    
# 37% are in cluster 1 (higher ratings) <- minorities
# 63% are in cluster 2 (lower ratings) <- non-minorities

# higher across the board for everything except for the flag for cancer 

```

#### Testing Data
```{r}

# Normalizing the data

z = test[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 60.7%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.5 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))
     
# 56% are in cluster 1 (lower ratings) <- non-minorities
# 44% are in cluster 2 (higher ratings) <- minorities

# higher across the board for everything except for the flag for cancer 


```

## Kings clustering analysis
### Base Model
#### Training Data
```{r}

eji_base_kings = eji_base[which(eji_base$COUNTY == 'Kings'),]
eji_base_kings = na.omit(eji_base_kings)

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_base_kings)), size = 524)
train = eji_base_kings[train_sample, ]
test = eji_base_kings[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 50%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
library(cluster)
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.42 <- could potentially have a better algorithm

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))
# 43% are in cluster 1 (lower ratings) <- non-minorities
# 57% are in cluster 2 (higher ratings) <- minorities

table(train$km.group, train$minority)

# cluster 1 has 11% of minority groups

# Are there significant differences?

aov_test = aov(RPL_EJI ~ km.group, data = train)
summary(aov_test) #yes there are significant differences 

aov_test = aov(RPL_SVM ~ km.group, data = train)
summary(aov_test) #yes there are significant differences 

aov_test = aov(E_PM ~ km.group, data = train)
summary(aov_test) #yes there are significant differences

```

#### Testing Data
```{r}

# Setting seed 
set.seed(123)

z = test[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 51.8%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.44 <- could potentially have a better algorithm

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))
# 35% are in cluster 1 (higher ratings) <- non-minorities
# 65% are in cluster 2 (lower ratings) <- minorities

table(test$km.group, test$minority)

# cluster 1 has 7% of minority groups

```

### More Complex Model
#### Training Data 
```{r}

eji_base_kings = eji_ny[which(eji_ny$COUNTY == 'Kings'),]
eji_base_kings = na.omit(eji_base_kings)

eji_complex_kings = eji_base_kings[, c("NAME", "COUNTY", "RPL_EJI", "EP_MINRTY", "EP_POV200",  "EP_NOHSDP", "EP_RENTER",  "EP_HOUBDN", "EPL_NOINT", "EP_ASTHMA","F_CANCER",  "EP_DIABETES",  "F_HVM",  "EP_MHLTH")]

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_complex_kings)), size = 524)
train = eji_complex_kings[train_sample, ]
test = eji_complex_kings[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 36.9%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.3 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))
                    
# 54% are in cluster 1 (higher ratings) <- non-minorities
# 46% are in cluster 2 (lower ratings) <- minorities

# higher across the board for everything (even cancer flag)

```

#### Testing Data
```{r}

# Normalizing the data

z = test[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 37.9%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.3 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))

# 51% are in cluster 1 (lower ratings) <- non-minorities
# 49% are in cluster 2 (higher ratings) <- minorities

# higher across the board for everything except for the flag for cancer 


```

## Queens clustering analysis
### Base Model
#### Training Data
```{r}

eji_base_queens = eji_base[which(eji_base$COUNTY == 'Queens'),]
eji_base_queens = na.omit(eji_base_queens)

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_base_queens)), size = 449)
train = eji_base_queens[train_sample, ]
test = eji_base_queens[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 50.5%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
library(cluster)
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.43 <- could potentially have a better algorithm

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))
# 43% are in cluster 1 (lower ratings) <- non-minorities
# 57% are in cluster 2 (higher ratings) <- minorities

table(train$km.group, train$minority)

# cluster 1 has 13% of minority groups

```

#### Testing Data
```{r}


# Setting seed 
set.seed(123)

z = test[, c(5:7)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 2 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 2)  # default gives 49%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.43 <- could potentially have a better algorithm
# all of cluster 1 remains under the average and has some negative values

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            E_PM = mean(E_PM),
            RPL_EJI = mean(RPL_EJI),
            RPL_SVM = mean(RPL_SVM))
# 42% are in cluster 1 (higher ratings) <- non-minorities
# 58% are in cluster 2 (lower ratings) <- minorities

table(test$km.group, test$minority)

# cluster 1 has 18% of minority groups

```

### More Complex Model
#### Training Data 
```{r}

eji_base_queens = eji_ny[which(eji_ny$COUNTY == 'Queens'),]
eji_base_queens = na.omit(eji_base_queens)

eji_complex_queens = eji_base_queens[, c("NAME", "COUNTY", "RPL_EJI", "EP_MINRTY", "EP_POV200",  "EP_NOHSDP", "EP_RENTER",  "EP_HOUBDN", "EPL_NOINT", "EP_ASTHMA","F_CANCER",  "EP_DIABETES",  "F_HVM",  "EP_MHLTH")]

# Setting seed 
set.seed(123)

train_sample = sample(seq_len(nrow(eji_complex_queens)), size = 449)
train = eji_complex_queens[train_sample, ]
test = eji_complex_queens[-train_sample, ]

# Training data
# Normalizing the data

z = train[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# How many clusters? 
fviz_nbclust(nor, kmeans, method = "silhouette") # 5 clusters

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 4)  # default gives 56.5%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.24 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
train = train %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2", "cl3", "cl4"))) 

# Summarizing the cluster groups
train %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))
                    
# 24% are in cluster 1 (minority
# 9% are in cluster 2 (minority) (always the highest except for cancer)
# 14% are in cluster 3 (non-minority) (usually always the lowest except for cancer)
# 34% are in cluster 4 (non-minority)
# 18% are in cluster 5 (minority)


```

#### Testing Data
```{r}
set.seed(123)

# Normalizing the data

z = test[, c(3:14)]
means = apply(z, 2, mean)
sds = apply(z, 2, sd)
nor = scale(z, center = means, scale = sds) 

# K Means on 2 Clusters
kmeans_result = kmeans(nor, centers = 5)  # default gives 58.8%
kmeans_result 

# Plot of Cluster
fviz_cluster(kmeans_result, data = nor)

# Silhouette coefficient
sil = as.data.frame(silhouette(kmeans_result$cluster, dist(nor)))
mean(sil$sil_width) # 0.26 <- worse than simplistic model

fviz_silhouette(silhouette(kmeans_result$cluster, dist(nor)))

# Adding Clusters to data set
test = test %>% 
  mutate(km.group = factor(kmeans_result$cluster, labels=c("cl1","cl2", "cl3", "cl4", "cl5"))) 

# Summarizing the cluster groups
test %>%
  group_by(km.group) %>%
  summarise(count = n(),
            RPL_EJI = mean(RPL_EJI),
            EP_MINRTY = mean(EP_MINRTY),
            EP_POV200 = mean(EP_POV200),
            EP_NOHSDP = mean(EP_NOHSDP),
            EP_RENTER = mean(EP_RENTER),
            EP_HOUBDN = mean(EP_HOUBDN),
            EPL_NOINT = mean(EPL_NOINT),
            EP_ASTHMA = mean(EP_ASTHMA),
            F_CANCER = mean(F_CANCER),
            EP_DIABETES = mean(EP_DIABETES),
            F_HVM = mean(F_HVM),
            EP_MHLTH = mean(EP_MHLTH))
                    
# 6% are in cluster 1 (non-minority)
# 24% are in cluster 2 (minority) 
# 33% are in cluster 3 (non-minority) 
# 9% are in cluster 4 (minority) (almost always the highest except for cancer)
# 28% are in cluster 5 (minority)
```


















